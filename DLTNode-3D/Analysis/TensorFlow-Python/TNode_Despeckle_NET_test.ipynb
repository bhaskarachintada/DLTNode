{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e762ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import pathlib\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095cf29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name   = \"Experiments_combined\"\n",
    "test_path  = \"despeckle/\" + \"Experiments_IV\" + \"/test_volumes/Volume_01\" # Test dataset directory \n",
    "train_path = \"despeckle/\" + exp_name + \"/test\" #Train dataset directory\n",
    "log_path   = \"despeckle/\" + exp_name + \"/logs\" # directory to save log files\n",
    "ckpt_path  = \"despeckle/\" + exp_name + \"/ckpt_32_32_16bit_Discriminator_126_126_latest\" # directory to save checkpoints\n",
    "save_dir   = \"/data/PersonalFolders/bhaskara/despeckle/\" + \"Experiments_IV\" + \"/result_volumes/Volume_01_3D_combined/\" # directory to save results\n",
    "isExist = os.path.exists(save_dir)\n",
    "if not isExist:\n",
    "    os.mkdir(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47074f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_path = train_path + \"/[p.SHARP][s.Eye2a][10-09-2019_13-14-42]_500.mat\"\n",
    "#try: \n",
    "#    sample_image = sio.loadmat(image_path)['bscanStack']\n",
    "#except:\n",
    "#    sample_image = sio.loadmat(image_path)['image_stack']\n",
    "##sample_image = tf.io.read_file(image_path)\n",
    "##sample_image = tf.io.decode_mat(sample_image)\n",
    "#print(sample_image.shape)\n",
    "#plt.figure()\n",
    "#im = plt.imshow(sample_image[:,:,0 ],cmap='gray')\n",
    "#plt.colorbar(im)\n",
    "#print(type(sample_image))\n",
    "#print(sample_image.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40a9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(image_path):\n",
    "  # Read and decode an image file to a uint8 tensor\n",
    "  def read_mat(image_path):\n",
    "    # Input mat files are 10*log10(tomogram intensity)\n",
    "    try:\n",
    "        image = sio.loadmat(image_path.numpy())['bscanStack']\n",
    "    except:\n",
    "        image = sio.loadmat(image_path.numpy())['image_stack']\n",
    "        \n",
    "    #noiseFloordB = np.round(np.mean(image[1:20,200:250,:]))\n",
    "#     noiseFloordB = noiseFloordB+2.50\n",
    "    noiseFloordB = 50;\n",
    "    maximumdB = 250;\n",
    "    # Compute the noise Floor\n",
    "#     try:\n",
    "#        ind = np.unravel_index(np.argmax(image, axis=None), image.shape)\n",
    "#        maximumdB = np.round(np.mean(image[ind(0)-5:ind(0)+5, ind(1)-5:ind(1)+5, ind(2)-2:ind(2)+2]))   \n",
    "#     except:\n",
    "#        maximumdB = np.max(image[:,:,8])\n",
    "                             \n",
    "    image = (image-noiseFloordB)/(maximumdB-noiseFloordB)\n",
    "    image = image*(2**16-1)\n",
    "    image = np.clip(image, 0, 2**16-1)\n",
    "    data = image.astype(np.uint16) \n",
    "    return data\n",
    "  image = tf.py_function(func=read_mat, inp=[image_path], Tout=tf.uint16)\n",
    "  #image = tf.convert_to_tensor(image, dtype=tf.uint8)\n",
    "  image = tf.image.convert_image_dtype(image, dtype=tf.uint16, saturate=False)\n",
    "  maxImageDimension = tf.math.reduce_max(tf.shape(image))\n",
    "  image = tf.image.resize_with_crop_or_pad(image, maxImageDimension, maxImageDimension)\n",
    "    # Convert both images to float32 tensors\n",
    "  input_image_stack = tf.cast(image, tf.float32)\n",
    "  #real_image = tf.cast(real_image, tf.float32)\n",
    "  return input_image_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644b40de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c894bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inp = load_test(image_path)\n",
    "## Casting to int for mat\n",
    "#print(inp.shape)\n",
    "##print(re.shape)\n",
    "\n",
    "#plt.figure(figsize=(15, 15))\n",
    "#for i in range(9):\n",
    "#  plt.subplot(3, 3, i+1)\n",
    "#  im = plt.imshow(inp[:,:, 2*i+1], vmin= 0, vmax= 2**16-1, cmap='gray')\n",
    "#  plt.axis('off')\n",
    "#  plt.colorbar(im)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4027c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(input_image_stack, height, width):\n",
    "  input_image_stack = tf.image.resize_with_crop_or_pad(input_image_stack, height, width)\n",
    "  #real_image = tf.image.resize(real_image, [height, width],method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "  return input_image_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff12e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the images to [-1, 1]\n",
    "def normalize(input_image_stack):\n",
    "  input_image_stack = (input_image_stack/(0.5*65535))-1\n",
    "  #input_image_stack = (input_image_stack / (0.5*tf.math.reduce_max(input_image_stack))) - 1\n",
    "  #real_image = (real_image / 127.5) - 1\n",
    "  return input_image_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc616d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The batch size of 1 produced better results for the U-Net in the original pix2pix experiment\n",
    "BATCH_SIZE = 1\n",
    "# Each image is 1024 x 1024 in size\n",
    "IMG_WIDTH = 1024\n",
    "IMG_HEIGHT = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff33502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_test(image_file):\n",
    "  input_image_stack = load_test(image_file)\n",
    "  input_image_stack = resize(input_image_stack, IMG_HEIGHT, IMG_WIDTH)\n",
    "  input_image_stack = normalize(input_image_stack)\n",
    "  return input_image_stack[:,:,:17], input_image_stack[:,:,17:], image_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac119b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inp, re, filename = load_image_test(image_path)\n",
    "#print(inp.shape)\n",
    "#print(re.shape)\n",
    "\n",
    "#im= plt.imshow(inp[:,:,8], cmap='gray')\n",
    "#plt.colorbar(im)\n",
    "#plt.axis('off')\n",
    "#plt.show()\n",
    "\n",
    "#im= plt.imshow(re, cmap='gray')\n",
    "#plt.colorbar(im)\n",
    "#plt.axis('off')\n",
    "#plt.show()\n",
    "\n",
    "#print(np.max(inp[:,:,8]))\n",
    "#print(np.max(inp))\n",
    "#print(np.max(re))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b90c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  test_dataset = tf.data.Dataset.list_files(test_path + \"/*.mat\")\n",
    "except tf.errors.InvalidArgumentError:\n",
    "  test_dataset = tf.data.Dataset.list_files(test_path + \"/*.mat\")\n",
    "print(test_dataset.cardinality().numpy())\n",
    "test_dataset = test_dataset.map(load_image_test)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6067dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18bd26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=True))\n",
    "\n",
    "  if apply_batchnorm:\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfc1dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(filters, size, apply_dropout=False):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "    tf.keras.layers.Conv2DTranspose(filters, size, strides = 2,\n",
    "                                    padding = 'same',\n",
    "                                    kernel_initializer = initializer,\n",
    "                                    use_bias = True))\n",
    "\n",
    "  result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  if apply_dropout:\n",
    "      result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f46fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator():\n",
    "  inputs = tf.keras.layers.Input(shape=[1024, 1024, 17])\n",
    "\n",
    "  down_stack = [\n",
    "    downsample(256, 4, apply_batchnorm=False),  # (batch_size, 512, 512, 64)\n",
    "    downsample(512, 4),  # (batch_size, 256, 256, 128)\n",
    "    downsample(1024, 4),  # (batch_size, 128, 128, 256)\n",
    "    downsample(2048, 4),  # (batch_size, 64, 64, 512)\n",
    "    downsample(2048, 4),  # (batch_size, 32, 32, 512)\n",
    "    #downsample(2048, 4),  # (batch_size, 16, 16, 512)\n",
    "    #downsample(2048, 4),  # (batch_size, 8, 8, 512)\n",
    "    #downsample(2048, 4),  # (batch_size, 4, 4, 512)\n",
    "    #downsample(2048, 4),  # (batch_size, 2, 2, 512)\n",
    "    #downsample(512, 4),  # (batch_size, 1, 1, 512)\n",
    "  ]\n",
    "\n",
    "  up_stack = [\n",
    "    #upsample(2048, 4, apply_dropout=True),  # (batch_size, 2, 2, 1024)\n",
    "    #upsample(2048, 4, apply_dropout=True),  # (batch_size, 4, 4, 1024)\n",
    "    #upsample(2048, 4),  # (batch_size, 8, 8, 1024)\n",
    "    upsample(2048, 4),  # (batch_size, 16, 16, 1024)\n",
    "    upsample(1024, 4),  # (batch_size, 32, 32, 1024)\n",
    "    #upsample(512, 4),  # (batch_size, 64, 64, 1024)\n",
    "    upsample(512, 4),  # (batch_size, 128, 128, 512)\n",
    "    upsample(256, 4),  # (batch_size, 256, 256, 256)\n",
    "    #upsample(64, 4),  # (batch_size, 512, 512, 128)\n",
    "  ]\n",
    "\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "  last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
    "                                         strides = 2,\n",
    "                                         padding = 'same',\n",
    "                                         kernel_initializer = initializer,\n",
    "                                         activation = 'tanh')  # (batch_size, 1024, 1024, 1)\n",
    "\n",
    "  x = inputs\n",
    "\n",
    "  # Downsampling through the model\n",
    "  skips = []\n",
    "  for down in down_stack:\n",
    "    x = down(x)\n",
    "    skips.append(x)\n",
    "\n",
    "  skips = reversed(skips[:-1])\n",
    "\n",
    "  # Upsampling and establishing the skip connections\n",
    "  for up, skip in zip(up_stack, skips):\n",
    "    x = up(x)\n",
    "    x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "  x = last(x)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db40b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f72f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Discriminator():\n",
    "#   initializer = tf.random_normal_initializer(0., 0.02)\n",
    "#   inp = tf.keras.layers.Input(shape=[1024, 1024, 17], name='input_image')\n",
    "#   tar = tf.keras.layers.Input(shape=[1024, 1024, 1], name='target_image')\n",
    "#   x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 1024, 1024, channels*2)\n",
    "#   down1 = downsample(256, 4, False)(x)  # (batch_size, 512, 512, 64)\n",
    "#   down2 = downsample(512, 4)(down1)  # (batch_size, 256, 256, 128)\n",
    "#   down3 = downsample(1024, 4)(down2)  # (batch_size, 128, 128, 256)\n",
    "#   #down4 = downsample(512, 4)(down3)  # (batch_size, 64, 64, 512)\n",
    "#   #down5 = downsample(1024, 4)(down4)  # (batch_size, 32, 32, 1024)\n",
    "#   zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (batch_size, 130, 130, 256)\n",
    "#   conv = tf.keras.layers.Conv2D(2048, 4, strides=1,\n",
    "#                                 kernel_initializer=initializer,\n",
    "#                                 use_bias=False)(zero_pad1)  # (batch_size, 127, 127, 512)\n",
    "#   batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "#   leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "#   zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 129, 129, 512)\n",
    "#   last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "#                                 kernel_initializer=initializer)(zero_pad2)  # (batch_size, 126, 126, 1)\n",
    "#   return tf.keras.Model(inputs=[inp, tar], outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edae51af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "  inp = tf.keras.layers.Input(shape=[1024, 1024, 17], name='input_image')\n",
    "  tar = tf.keras.layers.Input(shape=[1024, 1024, 1], name='target_image')\n",
    "  x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 1024, 1024, channels*2)\n",
    "  down1 = downsample(512, 4, False)(x)  # (batch_size, 512, 512, 64)\n",
    "  down2 = downsample(1024, 4)(down1)  # (batch_size, 256, 256, 128)\n",
    "  down3 = downsample(1024, 4)(down2)  # (batch_size, 128, 128, 256)\n",
    "  #down4 = downsample(512, 4)(down3)  # (batch_size, 64, 64, 512)\n",
    "  #down5 = downsample(1024, 4)(down4)  # (batch_size, 32, 32, 1024)\n",
    "  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (batch_size, 130, 130, 256)\n",
    "  conv = tf.keras.layers.Conv2D(2048, 4, strides=1,\n",
    "                                kernel_initializer=initializer,\n",
    "                                use_bias=False)(zero_pad1)  # (batch_size, 127, 127, 512)\n",
    "  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 129, 129, 512)\n",
    "  last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                kernel_initializer=initializer)(zero_pad2)  # (batch_size, 126, 126, 1)\n",
    "  return tf.keras.Model(inputs=[inp, tar], outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator()\n",
    "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f0ff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044fdf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"/data/PersonalFolders/bhaskara/\" + ckpt_path\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24bcfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8e67e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, tar, filename):\n",
    "  start =  time.time()\n",
    "  prediction = model(test_input, training=True)\n",
    "  timeExec = round(time.time()-start,3)  \n",
    "  print(f'Time taken: {time.time()-start:.2f} sec\\n')\n",
    "  panel = tf.concat([tf.squeeze(test_input[0][:,:,8]), tf.squeeze(tar[0]), tf.squeeze(prediction[0])],1)\n",
    "  panel = (panel+1)*32767.5\n",
    "  #panel = panel.astype(np.uint16)\n",
    "  #panel_cast = tf.cast((panel+1)*127.5, dtype='uint8')\n",
    "  #panel_cast = tf.cast((panel+1)*32767.5, dtype='uint16')\n",
    "  mdict = {\"outputStack\": panel.numpy()}\n",
    "  #panel = tf.expand_dims(panel,2)\n",
    "  #encoded = tf.io.encode_png(tf.cast((panel+1)*127.5, dtype='uint8'))\n",
    "  #encoded = tf.io.encode_png(tf.cast((tf.squeeze(prediction, axis = 0)+1)*127.5, dtype='uint8'))\n",
    "  #outputfile = tf.io.write_file(filename, encoded)\n",
    "  sio.savemat(filename, mdict)\n",
    "  plt.figure(figsize=(15, 15))\n",
    "  display_list = [test_input[0][:,:,8], tar[0], prediction[0]]\n",
    "  mae = tf.keras.losses.MeanAbsoluteError()\n",
    "  print(f'L1_error:{mae(tar[0], prediction[0]).numpy()}')\n",
    "  title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "  for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.title(title[i])\n",
    "    # Getting the pixel values in the [0, 1] range to plot.\n",
    "    im = plt.imshow(tf.squeeze((display_list[i]+1)*32767.5), cmap='gray')\n",
    "    #plt.colorbar(im)\n",
    "    plt.axis('off')   \n",
    "  plt.show()\n",
    "  return timeExec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8f85d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# print(log_path)\n",
    "# log_dir = \"/data/PersonalFolders/bhaskara/\" + log_path\n",
    "# %reload_ext tensorboard\n",
    "# %tensorboard --logdir \"/data/PersonalFolders/bhaskara/despeckle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4da68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f102040",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52c5f47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the trained model on a few examples from the test set\n",
    "all = test_dataset.cardinality().numpy()\n",
    "timeExeclist = []\n",
    "for inp, tar, img in test_dataset.take(all):\n",
    "  f_name = str(img.numpy())\n",
    "  #f_name = save_dir + f_name\n",
    "  f_name = f_name.split('/')[-1]\n",
    "  f_name = f_name[:-2]\n",
    "  f_name = save_dir + f_name \n",
    "  print(f_name)\n",
    "  timeExec = generate_images(generator, inp, tar, f_name)\n",
    "  timeExeclist.append(timeExec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6383ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(timeExeclist[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6957e17b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b52491a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5fbfdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95730ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50329338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
